#!/usr/bin/env python3
"""
Analyze token values at each step within a single OpenCode session.
Shows cache growth over time and highlights DCP tool usage that causes cache drops.

Queries the OpenCode SQLite database directly for fast, offline access.

Usage: opencode-session-timeline [--session ID] [--json] [--no-color] [--db PATH]
"""

import argparse
import json
from typing import Optional

from opencode_api import APIError, add_api_arguments, create_client_from_args, list_sessions_across_projects


DCP_TOOLS = {
    "compress",
    "prune",
    "distill",
    "discard",
    "extract",
    "context_pruning",
    "squash",
    "consolidate",
}


class Colors:
    RESET = "\033[0m"
    BOLD = "\033[1m"
    DIM = "\033[2m"
    RED = "\033[31m"
    GREEN = "\033[32m"
    YELLOW = "\033[33m"
    CYAN = "\033[36m"


NO_COLOR = Colors()
for attr in dir(NO_COLOR):
    if not attr.startswith("_"):
        setattr(NO_COLOR, attr, "")


def format_duration(ms: Optional[int]) -> str:
    if ms is None:
        return "-"
    seconds = ms / 1000
    if seconds < 60:
        return f"{seconds:.1f}s"
    if seconds < 3600:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}m{secs:.0f}s"
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    return f"{hours}h{minutes}m"


def extract_step_data(parts: list[dict]) -> Optional[dict]:
    step_finish = None
    tools_used = []
    dcp_tools_used = []

    for part in parts:
        if part.get("type") == "step-finish" and "tokens" in part:
            step_finish = part
        elif part.get("type") == "tool":
            tool_name = part.get("tool", "")
            tools_used.append(tool_name)
            if tool_name in DCP_TOOLS:
                dcp_tools_used.append(tool_name)

    if step_finish is None:
        return None

    tokens = step_finish.get("tokens", {})
    cache = tokens.get("cache", {})
    return {
        "input": tokens.get("input", 0),
        "output": tokens.get("output", 0),
        "reasoning": tokens.get("reasoning", 0),
        "cache_read": cache.get("read", 0),
        "cache_write": cache.get("write", 0),
        "cost": step_finish.get("cost", 0),
        "reason": step_finish.get("reason", "unknown"),
        "tools_used": tools_used,
        "dcp_tools_used": dcp_tools_used,
        "has_dcp": len(dcp_tools_used) > 0,
    }


def get_most_recent_session(client, session_list_limit: int) -> Optional[dict]:
    sessions = list_sessions_across_projects(client, per_project_limit=session_list_limit)
    return sessions[0] if sessions else None


def analyze_session(client, session: dict) -> dict:
    session_id = session["id"]
    messages = client.get_session_messages(session_id, directory=session.get("directory"))
    title = session.get("title", "Unknown")

    steps = []
    for message in messages:
        info = message.get("info", {})
        parts = message.get("parts", [])
        step_data = extract_step_data(parts)
        if not step_data:
            continue
        time_info = info.get("time", {})
        step_data["message_id"] = info.get("id", "")
        step_data["created"] = time_info.get("created")
        step_data["completed"] = time_info.get("completed")
        steps.append(step_data)

    for idx, step in enumerate(steps):
        if idx == 0:
            step["cache_read_delta"] = step["cache_read"]
            step["input_delta"] = step["input"]
            step["time_since_prev_ms"] = None
        else:
            prev = steps[idx - 1]
            step["cache_read_delta"] = step["cache_read"] - prev["cache_read"]
            step["input_delta"] = step["input"] - prev["input"]
            prev_completed = prev.get("completed")
            created = step.get("created")
            step["time_since_prev_ms"] = (created - prev_completed) if (prev_completed and created) else None

        created = step.get("created")
        completed = step.get("completed")
        step["duration_ms"] = (completed - created) if (created and completed) else None

        total_context = step["input"] + step["cache_read"]
        step["cache_hit_rate"] = (step["cache_read"] / total_context * 100) if total_context > 0 else 0

    total_input = sum(s["input"] for s in steps)
    total_output = sum(s["output"] for s in steps)
    total_cache_read = sum(s["cache_read"] for s in steps)
    total_cost = sum(s["cost"] for s in steps)
    total_duration_ms = sum((s["duration_ms"] or 0) for s in steps)
    total_dcp_tools = sum(len(s["dcp_tools_used"]) for s in steps)
    
    total_context = total_input + total_cache_read
    avg_cache_hit_rate = (total_cache_read / total_context * 100) if total_context > 0 else 0

    return {
        "session_id": session_id,
        "title": title,
        "steps": steps,
        "total_steps": len(steps),
        "total_input": total_input,
        "total_output": total_output,
        "total_cache_read": total_cache_read,
        "total_cost": total_cost,
        "total_duration_ms": total_duration_ms,
        "total_dcp_tools": total_dcp_tools,
        "avg_cache_hit_rate": avg_cache_hit_rate,
    }


def print_timeline(result: dict, colors: Colors):
    c = colors
    print(f"{c.BOLD}{'=' * 130}{c.RESET}")
    print(f"{c.BOLD}SESSION TIMELINE: Token Values at Each Step{c.RESET}")
    print(f"{c.BOLD}{'=' * 130}{c.RESET}\n")
    print(f"  Session: {c.CYAN}{result['session_id']}{c.RESET}")
    print(f"  Title:   {result['title']}")
    print(f"  Steps:   {result['total_steps']}\n")

    if not result["steps"]:
        print("  No steps found in this session.")
        return

    print(
        f"{c.BOLD}{'Step':<6} {'Cache Read':>12} {'Î” Cache':>12} {'Input':>10} {'Output':>10} {'Cache %':>9} {'Duration':>10} {'Gap':>10} {'DCP Tools':<15} {'Reason':<12}{c.RESET}"
    )
    print("-" * 130)

    for idx, step in enumerate(result["steps"], 1):
        cache_delta = step["cache_read_delta"]
        if cache_delta > 0:
            delta = f"{c.GREEN}{'+' + f'{cache_delta:,}':>11}{c.RESET}"
        elif cache_delta < 0:
            delta = f"{c.RED}{f'{cache_delta:,}':>12}{c.RESET}"
        else:
            delta = f"{c.DIM}{'0':>12}{c.RESET}"

        pct = step["cache_hit_rate"]
        if pct >= 80:
            pct_str = f"{c.GREEN}{pct:>8.1f}%{c.RESET}"
        elif pct >= 50:
            pct_str = f"{c.YELLOW}{pct:>8.1f}%{c.RESET}"
        else:
            pct_str = f"{c.RED}{pct:>8.1f}%{c.RESET}"

        dcp_str = f"{c.YELLOW}{', '.join(step['dcp_tools_used'])}{c.RESET}" if step["has_dcp"] else f"{c.DIM}-{c.RESET}"
        row_prefix = f"{c.YELLOW}{c.BOLD}" if step["has_dcp"] else ""
        row_suffix = c.RESET if step["has_dcp"] else ""

        print(
            f"{row_prefix}{idx:<6}{row_suffix} {step['cache_read']:>12,} {delta} {step['input']:>10,} {step['output']:>10,} {pct_str} {format_duration(step.get('duration_ms')):>10} {format_duration(step.get('time_since_prev_ms')):>10} {dcp_str:<15} {step['reason']:<12}"
        )

    print("-" * 130)

    print(f"\n{c.BOLD}SESSION SUMMARY{c.RESET}")
    print(f"  Total Input Tokens:  {result.get('total_input', 0):,}")
    print(f"  Total Output Tokens: {result.get('total_output', 0):,}")
    print(f"  Total Cache Read:    {result.get('total_cache_read', 0):,}")
    
    avg_pct = result.get('avg_cache_hit_rate', 0)
    if avg_pct >= 80:
        avg_pct_str = f"{c.GREEN}{avg_pct:.1f}%{c.RESET}"
    elif avg_pct >= 50:
        avg_pct_str = f"{c.YELLOW}{avg_pct:.1f}%{c.RESET}"
    else:
        avg_pct_str = f"{c.RED}{avg_pct:.1f}%{c.RESET}"
        
    print(f"  Avg Cache Hit Rate:  {avg_pct_str}")
    print(f"  Total Cost:          ${result.get('total_cost', 0):.4f}")
    print(f"  Total Duration:      {format_duration(result.get('total_duration_ms', 0))}")
    print(f"  Total DCP Uses:      {result.get('total_dcp_tools', 0)}")


def main():
    parser = argparse.ArgumentParser(description="Analyze token values at each step within an OpenCode session")
    parser.add_argument("--session", "-s", type=str, default=None, help="Session ID to analyze (default: most recent)")
    parser.add_argument("--json", "-j", action="store_true", help="Output as JSON")
    parser.add_argument("--no-color", action="store_true", help="Disable colored output")
    add_api_arguments(parser)
    args = parser.parse_args()

    try:
        with create_client_from_args(args) as client:
            if args.session is None:
                session = get_most_recent_session(client, args.session_list_limit)
                if session is None:
                    print("Error: No sessions found")
                    return 1
            else:
                session = client.get_session(args.session)
            result = analyze_session(client, session)
    except APIError as err:
        print(f"Error: {err}")
        return 1

    if args.json:
        print(json.dumps(result, indent=2, default=str))
    else:
        colors = NO_COLOR if args.no_color else Colors()
        print_timeline(result, colors)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
